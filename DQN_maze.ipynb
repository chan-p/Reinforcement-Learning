{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     25
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "import chainer\n",
    "from chainer import Function, Variable, optimizers, serializers\n",
    "from chainer import Link, Chain\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import copy\n",
    "\"\"\"\n",
    "MAZE = [[-1,-1,-1,-1,-1,-1,-1,-1,-1,-1],\n",
    "        [-1, 0, 0, 0, 0, 0, 0, 0, 0,-1],\n",
    "        [-1,-1,-1,-1,-1, 0,-1,-1, 0,-1],\n",
    "        [-1,-1, 0, 0, 0, 0, 0,-1, 0,-1],\n",
    "        [-1, 0,-1,-1,-1,-1,-1,-1, 0,-1],\n",
    "        [-1, 0,-1, 0, 0, 0, 0, 0, 0,-1],\n",
    "        [-1, 0,-1,-1,-1,-1,-1,-1, 0,-1],\n",
    "        [-1, 0, 0, 0, 0, 0, 0, 0, 0,-1],\n",
    "        [-1,-1, 0,-1,-1,-1,-1,-1,-9,-1],\n",
    "        [-1,-1, 0, 0, 0, 0, 0, 0, 1,-1],\n",
    "        [-1,-1,-1,-1,-1,-1,-1,-1,-1,-1]]\n",
    "\"\"\"\n",
    "MAZE = [[-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1],\n",
    "        [-1, 0, 0, 0, 0, 0, 0, 0, 0,-1,-1,-1],\n",
    "        [-1,-1,-1,-1,-1, 0,-1,-1, 0,-1,-1,-1],\n",
    "        [-1,-1, 0, 0, 0, 0, 0,-1, 0,-1,-1,-1],\n",
    "        [-1, 0,-1,-1,-1,-1,-1,-1, 0,-1,-1,-1],\n",
    "        [-1, 0, 0, 0, 0, 0, 0, 0 ,0,-1,-1,-1],\n",
    "        [-1, 0,-1,-1,-1,-1,-1,-1, 0,-1,-1,-1],\n",
    "        [ 0, 0, 0, 0, 0, 0, 0, 0, 0,-1,-1,-1],\n",
    "        [ 0,-1, 0,-1,-1,-1,-1,-1,-1,-1,-1,-1],\n",
    "        [ 0,-1, 0, 0, 0, 0, 0, 0, 0,-1,-1,-1],\n",
    "        [ 0,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1],\n",
    "        [ 0,-1, 0, 0, 0, 0,-1, 0, 0, 0, 1,-1],\n",
    "        [ 0, 0, 0,-1,-1, 0, 0, 0,-1,-1,-1,-1]]\n",
    "START  = (1, 1)\n",
    "ACTION = [(-1, 0), (1, 0), (0, -1), (0, 1)] # [上, 下, 左, 右]\n",
    "EPOCH  = 30\n",
    "RESULT = []\n",
    "NUM_IN   = (len(MAZE)+1) * (len(MAZE[0])+1)\n",
    "NUM_HID1 = 1000\n",
    "NUM_HID2 = 500\n",
    "NUM_HID3 = 250\n",
    "NUM_OUT  = 4\n",
    "BATCH_SIZE = 32\n",
    "ALPH   = 0.1\n",
    "GAMMA  = np.array([0.99 for i in range(BATCH_SIZE)], np.float32)\n",
    "\n",
    "def deep_q_learn(q_network, target_network, records):\n",
    "    file = open(\"/Users/chan-p/Desktop/action2.txt\", \"w\")\n",
    "    result_list  = []\n",
    "    next_records = []\n",
    "    best_records = []\n",
    "    state_index  = init_index()\n",
    "    EPSIL  = 0.1\n",
    "    state_vecs, actions, rewords ,next_state_vecs, terminals, next_states, now_states= translate(records)\n",
    "    for epoch in range(1, EPOCH+1):\n",
    "        EPSIL = decay_EPSIL(epoch, EPSIL)\n",
    "        state_vec = init_state_vec()\n",
    "        now_state = START\n",
    "        state_vec[state_index[START]] = 1\n",
    "        record_write(file, 0, 0, 3)\n",
    "        episode_records = []\n",
    "        while True:\n",
    "            # 状態sをDNN用にベクトル化\n",
    "            state_vec = get_state_vec(state_vec)\n",
    "            # 状態sをDNNの入力として状態sにおける各行動aの行動価値を算出：Q(s,a)\n",
    "            # 方策：e-greedy\n",
    "            if epoch < EPOCH*(1/100):\n",
    "                action, q_max, action_list = policy_egreedy(state_vec, q_network, EPSIL)\n",
    "            else:\n",
    "                action, q_max, action_list = policy_greedy_tri(state_vec, q_network, EPSIL)\n",
    "            # 次の状態s'を決定\n",
    "            next_state = get_next_state(now_state, action)\n",
    "            # 次の状態が迷路外ならエピソード終了\n",
    "            if state_check(next_state) == 0 or MAZE[next_state[0]][next_state[1]] == -1:\n",
    "                print(now_state)\n",
    "                # 罰則による学習\n",
    "                deep_learn(q_network, target_network, state_vec, now_state, next_state, 0)\n",
    "                record_write(file, action[0], action[1], 1)\n",
    "                next_records.append((now_state, action, -1, 1))\n",
    "                next_records.extend(episode_records)\n",
    "                result_list.append(0)\n",
    "                break\n",
    "            # 即時報酬\n",
    "            reward = MAZE[next_state[0]][next_state[1]]\n",
    "            if reward == 1:\n",
    "                print(epoch)\n",
    "                # 成功報酬による学習\n",
    "                deep_learn(q_network, target_network, state_vec, now_state, next_state, 0)\n",
    "                record_write(file, 0, 0, 2)\n",
    "                # 成功体験を優先してExperiment_Replayレコードに追加\n",
    "                best_records.append((now_state, action, 1, 1))\n",
    "                best_records.extend(episode_records)\n",
    "                result_list.append(1)\n",
    "                break\n",
    "            # 実行動による学習\n",
    "            deep_learn(q_network, target_network, state_vec, now_state, next_state, 1)\n",
    "            # Experiment_Replayレコードに追加\n",
    "            episode_records.append((now_state, action, reward, 0))\n",
    "            record_write(file, action[0], action[1], 0)\n",
    "            now_state = next_state\n",
    "            state_vec = init_state_vec()\n",
    "            state_vec[state_index[now_state]] = 1\n",
    "\n",
    "            # 学習\n",
    "            # experiment_replayによるバッチ学習\n",
    "            perm = np.random.permutation(len(records))[:BATCH_SIZE]\n",
    "            x_batch_state   = state_vecs[perm[0:BATCH_SIZE]]\n",
    "            x_batch_action  = actions[perm[0:BATCH_SIZE]]\n",
    "            x_batch_rewords = rewords[perm[0:BATCH_SIZE]]\n",
    "            x_batch_now_state = []\n",
    "            x_batch_next_state = []\n",
    "            for index in perm:\n",
    "                x_batch_now_state.append(now_states[index])\n",
    "                x_batch_next_state.append(next_states[index])\n",
    "            x_batch_next_state_vec = next_state_vecs[perm[0:BATCH_SIZE]]\n",
    "            y_batch_target = []\n",
    "            # ニューラルの重み更新\n",
    "            for index in range(BATCH_SIZE):\n",
    "                y_batch_target.append(deep_learn(q_network, target_network, x_batch_state[index], x_batch_now_state[index], x_batch_next_state[index], 1))\n",
    "            y_batch_target = np.array(y_batch_target, dtype=np.float32)\n",
    "            q_network.init_grads()\n",
    "            loss = q_network.forward(1, x_batch_state, y_batch_target)\n",
    "            q_network.backpropagation(loss)\n",
    "              \n",
    "        # レコードの更新\n",
    "        if len(next_records) + len(best_records) > 5000:\n",
    "            best_records.extend(next_records)\n",
    "            state_vecs, actions, rewords ,next_state_vecs, terminals, next_states, now_states = translate(best_records)\n",
    "            records = copy.copy(best_records)\n",
    "            if len(best_records) > 5000:\n",
    "                best_records = []\n",
    "            next_records = []\n",
    "        \n",
    "        # target networkの更新\n",
    "        if epoch % 5 == 0:\n",
    "            print(epoch)\n",
    "            target_network = update_target_network(q_network)\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            q_network.save_weight()\n",
    "            \n",
    "    file.close()\n",
    "    return result_list\n",
    "\n",
    "def init_state_vec():\n",
    "    return np.array([0 for i in range(NUM_IN)], dtype=np.float32)\n",
    "\n",
    "def get_state_vec(state_vec):\n",
    "    return np.array([state_vec], dtype = np.float32)\n",
    "\n",
    "def get_next_state(state, action):\n",
    "    return (state[0]+action[0], state[1]+action[1])\n",
    "\n",
    "def deep_learn(q_network, target_network, state_vec, now_state, next_state, flg):\n",
    "    y_targets = []\n",
    "    state_index = init_index()\n",
    "    for action in ACTION:\n",
    "        next_state_vec = init_state_vec()\n",
    "        next_state = get_next_state(now_state, action)\n",
    "        # 次の状態が迷路外\n",
    "        # 報酬(罰則)のみ\n",
    "        if next_state[0] < 0 or next_state[0] > len(MAZE)-1 or next_state[1] > len(MAZE[0])-1 or next_state[1] < 0 or MAZE[next_state[0]][next_state[1]] == -1:\n",
    "            y_target = -2\n",
    "        else:\n",
    "            next_state_vec[state_index[(next_state[0], next_state[1])]] = 1\n",
    "            next_actions = target_network.forward(0, np.array([next_state_vec], dtype=np.float32))\n",
    "            max_q = np.max(next_actions.data[0], axis = 0)\n",
    "            y_target = MAZE[next_state[0]][next_state[1]] + 0.1 * max_q\n",
    "        y_targets.append(y_target)\n",
    "    y_targets = np.array(y_targets, dtype=np.float32)\n",
    "    if flg: return y_targets\n",
    "    y_target = np.array([y_targets], dtype=np.float32)\n",
    "    q_network.init_grads()\n",
    "    loss = q_network.forward(1, state_vec, y_target)\n",
    "    q_network.backpropagation(loss)\n",
    "\n",
    "def update_target_network(q_network):\n",
    "    return copy.deepcopy(q_network)\n",
    "\n",
    "def state_check(state):\n",
    "    if (state[0] < 0) or (state[1] < 0) or (len(MAZE)-1) < state[0] or (len(MAZE[0])-1 < state[1]):\n",
    "        RESULT.append(0)\n",
    "        return 0\n",
    "    return 1 \n",
    "\n",
    "def policy_egreedy(state, neural, EPSIL):\n",
    "    qvalue = neural.forward(0, state).data[0]\n",
    "    return (ACTION[random.choice([i for i, x in enumerate(qvalue) if x == max(qvalue)])] if EPSIL < random.random() else random.choice(ACTION)), max(qvalue), qvalue           \n",
    "\n",
    "def policy_greedy_tri(state, neural, EPSIL):\n",
    "    import scipy.spatial.distance\n",
    "    qvalue_list = []\n",
    "    tmp = []\n",
    "    qvalue_list.append(neural.forward(0, state).data[0])\n",
    "    qvalue_list.append(neural.forward(0, state).data[0])\n",
    "    qvalue_vec = np.array(neural.forward(0, state).data[0])\n",
    "    for qvalue in qvalue_list:\n",
    "        sim = 1 - scipy.spatial.distance.cosine(np.array(qvalue), qvalue_vec)\n",
    "        tmp.append(sim)\n",
    "    if tmp[0] < tmp[1]:\n",
    "        return ACTION[list(qvalue_list[1]).index(max(qvalue_list[1]))], max(qvalue_list[1]), qvalue_list[1]\n",
    "    else:\n",
    "        return ACTION[list(qvalue_list[0]).index(max(qvalue_list[0]))], max(qvalue_list[0]), qvalue_list[0]\n",
    "\n",
    "def translate(records):\n",
    "    now_states = []\n",
    "    state_vecs  = []\n",
    "    actions = []\n",
    "    rewords = []\n",
    "    next_states = []\n",
    "    terminals = []\n",
    "    next_state_vecs = []\n",
    "    state_index = init_index()\n",
    "    state_vec = np.array([0 for i in range(NUM_IN)], dtype=np.float32)\n",
    "    next_state_vec = np.array([0 for i in range(NUM_IN)], dtype=np.float32)\n",
    "    for record in records:\n",
    "        now_states.append(record[0])\n",
    "        next_state = (record[0][0]+record[1][0], record[0][1]+record[1][1])\n",
    "        next_states.append(next_state)\n",
    "        state_vec = np.array([0 for i in range(NUM_IN)], dtype=np.float32)\n",
    "        state_vec[state_index[record[0]]] = 1\n",
    "        state_vecs.append(state_vec)\n",
    "        actions.append(record[1])\n",
    "        rewords.append(record[2])\n",
    "        terminals.append(record[3])\n",
    "        if record[3] == 1:\n",
    "            next_state_vec = np.array([0 for i in range(NUM_IN)], dtype=np.float32)\n",
    "            next_state_vecs.append(next_state_vec)\n",
    "        else:\n",
    "            next_state_vec = np.array([0 for i in range(NUM_IN)], dtype=np.float32)\n",
    "            next_state_vec[state_index[next_state]] = 1\n",
    "            next_state_vecs.append(next_state_vec)\n",
    "    return np.array(state_vecs, dtype=np.float32), np.array(actions), np.array(rewords, dtype=np.float32), np.array(next_state_vecs, dtype=np.float32), np.array(terminals, dtype=np.float32), next_states, now_states\n",
    "\n",
    "def experience_replay():\n",
    "    records = []\n",
    "    with open(\"./record.csv\") as f:\n",
    "        for line in f:\n",
    "            line   = line[:-1].split(\",\")\n",
    "            state  = (int(line[0]), int(line[1]))\n",
    "            action = (int(line[2]), int(line[3]))\n",
    "            reword = int(line[4])\n",
    "            terminal = int(line[5])\n",
    "            record = (state, action, reword, terminal)\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "def record_write(file, state_y, state_x, terminal):\n",
    "    file.write(str(state_y) + \",\" + str(state_x) + \",\" +str(terminal) + \"\\n\")\n",
    "\n",
    "def init_index():\n",
    "    qtable_index = {}\n",
    "    num = 0\n",
    "    for y in range(len(MAZE)+1):\n",
    "        for x in range(len(MAZE[0])+1):\n",
    "            qtable_index[(y, x)] = num\n",
    "            num += 1\n",
    "    return qtable_index\n",
    "\n",
    "def decay_EPSIL(epoch, EPSIL):\n",
    "    if epoch > (EPOCH/3)*2:\n",
    "        return EPSIL/(epoch)*(EPOCH/10)\n",
    "    return EPSIL\n",
    "\n",
    "def main():\n",
    "    q_network = NeuralNetwork(NUM_IN, NUM_HID1, NUM_HID2, NUM_HID3, NUM_OUT)\n",
    "    target_network = NeuralNetwork(NUM_IN, NUM_HID1, NUM_HID2, NUM_HID3, NUM_OUT)\n",
    "    q_network.load_weight()\n",
    "    target_network = update_target_network(q_network)\n",
    "    return deep_q_learn(q_network, target_network, experience_replay())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "(12, 0)\n",
      "(12, 7)\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "10\n",
      "11\n",
      "12\n",
      "(3, 6)\n",
      "14\n",
      "15\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "(12, 2)\n",
      "20\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkRNyPlnYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118fdcac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_list = main()\n",
    "gragh(_list, len(_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import chainer\n",
    "from chainer import Function, Variable, optimizers, serializers\n",
    "from chainer import Link, Chain\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, num_in, num_hid1, num_hid2, num_hid3, num_out):\n",
    "        self.model = Chain(hid_layer1 = L.Linear(num_in, num_hid1),\n",
    "                           hid_layer2 = L.Linear(num_hid1, num_hid2),\n",
    "                           hid_layer3 = L.Linear(num_hid2, num_hid3),\n",
    "                           out_layer  = L.Linear(num_hid3, num_out))\n",
    "        self.optimizer = optimizers.Adam()\n",
    "        self.optimizer.setup(self.model)\n",
    "    \n",
    "    def forward(self, flg, x, t = None):\n",
    "        _x = Variable(x)\n",
    "        if flg == 1: _t = Variable(t)\n",
    "        h1  = F.dropout(F.relu(self.model.hid_layer1(_x)))\n",
    "        h2  = F.dropout(F.relu(self.model.hid_layer2(h1)))\n",
    "        h3  = F.dropout(F.relu(self.model.hid_layer3(h2)))\n",
    "        u3  = self.model.out_layer(h3)\n",
    "        # return F.softmax_cross_entropy(u2, _t) if flg else F.softmax(u2)\n",
    "        # return F.mean_squared_error(self.policy_greedy(u3), _t) if flg else u3\n",
    "        return F.mean_squared_error(u3, _t) if flg else u3\n",
    "    \n",
    "    def backpropagation(self, loss):\n",
    "        loss.backward()\n",
    "        self.optimizer.update()\n",
    "    \n",
    "    def init_grads(self):\n",
    "        self.optimizer.zero_grads()\n",
    "        \n",
    "    def save_weight(self):\n",
    "        serializers.save_npz(\"my.model\", self.model)\n",
    "        \n",
    "    def load_weight(self):\n",
    "        serializers.load_npz(\"my.model\", self.model)\n",
    "        \n",
    "    def policy_greedy(self, actions):\n",
    "        return np.max(actions.data, axis = 1)\n",
    "    \n",
    "class Gragh:\n",
    "    def gragh(result, epoch):    \n",
    "        x = np.arange(0, epoch, 1)\n",
    "        left = np.array(x)\n",
    "        count = 0\n",
    "        count_1 = 0\n",
    "        parcent = []\n",
    "        for i in result:\n",
    "            count += 1\n",
    "            if i == 1:\n",
    "                count_1 += 1\n",
    "            parcent.append(count_1/count)\n",
    "        height = np.array(parcent)\n",
    "        plt.plot(left, height)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def gragh(result, epoch):    \n",
    "    x = np.arange(0, epoch, 1)\n",
    "    left = np.array(x)\n",
    "    count = 0\n",
    "    count_1 = 0\n",
    "    parcent = []\n",
    "    for i in result:\n",
    "        count += 1\n",
    "        if i == 1:\n",
    "            count_1 += 1\n",
    "        parcent.append(count_1/count)\n",
    "    height = np.array(parcent)\n",
    "    plt.plot(left, height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
